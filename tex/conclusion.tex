\section{Conclusion}\label{sec:conclusion}

In this paper, we review state-of-the-art neural network accelerator designs and summarize the techniques used. According to the evaluation result in section~\ref{sec:evaluation}, with software hardware co-design, FPGA can achieve more than $10\times$ better speed and energy efficiency than state-of-the-art GPU. This shows that FPGA is a promising candidate for neural network acceleration. We also review the methods used for accelerator design automation, which shows that current development flow can achieve both high performance and run-time network switch.

But there is still a gap between current designs and the estimation. On the one hand, quantization with extremely narrow bit-width is limited by the model accuracy, which needs further algorithm research. On the other hand, combining all the techniques needs more research in both software and hardware to make them work well together. Commercial tools including DNNDK~\cite{dnndk} is taking a first step but still has a lone way to go. Scaling up the design is also a problem. Future work should focus on solving these challenges. 