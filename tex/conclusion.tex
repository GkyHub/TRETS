\section{Conclusion}\label{sec:conclusion}

In this paper, we review state-of-the-art neural network accelerator designs and summarize the techniques used. According to the evaluation result in section~\ref{sec:evaluation}, with software hardware co-design, FPGA can achieve $13\times$ better energy efficiency than state-of-the-art GPU while using $30\%$ power with conservative estimation. This shows that FPGA is a promising candidate for neural network acceleration. We also review the methods used for flexible accelerator design, which shows that current development flow can achieve both high performance and run-time network switch.

But there is still a gap between current designs and the estimation. Combining all the techniques requires software-hardware co-design. Using quantization and weight reduction together while maintaining the performance is challenging. Scaling up the design is another problem. Future work should focus on solving these challenges. There is still $10\times$ potential performance gain from using $1/2$ bits for neuron and weight representation. Future work should try to improve the model accuracy in these cases.