\begin{table}[htbp]
    \centering
    \caption{Performance and resource utilization of state-of-the-art neural network accelerator designs}
    \begin{tabular}{r|c|c|c|c|ccc|c}
        \toprule
        \multicolumn{1}{c|}{} & Data  & Speed & Power & Eff. & \multicolumn{3}{c|}{Resource(\%)} & \multirow{2}[4]{*}{FPGA chip} \\ %\cline{6-8}
        \multicolumn{1}{c|}{} & Format & (GOP/s) & (W)   & (GOP/J) & DSP   & logic & BRAM  &  \\
        \hline
            \cite{nakahara2017fully}    & 1bit      & 329.47    & 2.3   & 143.2 & 1     & 34    & 11    & Zynq XC7Z020 \\ 
            \cite{moss2017high}         & 1bit      & 40770     & 48    & 849.38 &   -   &   -   &   -   & GX1155 \\ 
            \cite{jiao2017accelerating} & 2bit      & 410.22    & 2.26  & 181.51 & 41   & 83    & 38    & Zynq XC7Z020 \\ 
            \cite{guo2017angel}         & INT8      & 84.3      & 3.5   & 24.1  & 87    & 84    & 89    & XC7Z020 \\ 
            \cite{suda2016throughput}   & INT16/8   & 117.8     & 19.1  & 6.2   & 13    & 22    & 65    & 5SGSD8 \\ 
            \cite{liu2016automatic}     & INT16/8   & 222.1     & 24.8  & 8.96  & 40    & 27    & 40    & XC7VX690T \\ 
            \cite{ma2017optimizing}     & INT16/8   & 645.25    & 21.2  & 30.43 & 100   & 38    & 70    & GX1150 \\             
            \cite{han2017ese}           & INT16/12  & 2520      & 41    & 61.5  & 54    & 89    & 88    & XCKU060 \\ 
            \cite{venieris2017fpgaconvnet} & INT16  & 12.73     & 1.75  & 7.27  & 95    & 67    & 6     & XC7Z020 \\ 
            \cite{qiu2016going}         & INT16     & 136.97    & 9.63  & 14.22 & 89    & 84    & 87    & XC7Z045 \\ 
            \cite{xiao2017exploring}    & INT16     & 229.5     & 9.4   & 24.42 & 92    & 71    & 83    & XC7Z045 \\ 
            \cite{zhang2016caffeine}    & INT16     & 354       & 26    & 13.6  & 78    & 81    & 42    & XC7VX690T \\ 
            \cite{guan2017fp}           & INT16     & 364.4     & 25    & 14.6  & 65    & 25    & 46    & 5SGSMD5 \\ 
            \cite{li2016high}           & INT16     & 565.94    & 30.2  & 22.15 & 60    & 63    & 65    & XC7VX690T \\ 
            \multirow{2}[2]{*}{\cite{Shen2018Towards}} & \multirow{2}[2]{*}{INT16} & 431  & 25 & 17.1  & 42 & 56 & 52    & XC7VX690T \\ %\cline{3-9}    
             &  & 785 & 26 & 30.2 & 53 & 8.3  & 30 & XCVU440 \\ %\hline
            \multirow{2}[2]{*}{\cite{zhang2016energy}} & \multirow{2}[0]{*}{INT16} & \multirow{2}[0]{*}{1280.3} & \multirow{2}[0]{*}{160} & \multirow{2}[0]{*}{8} & \multirow{2}[0]{*}{-} & \multirow{2}[0]{*}{-} & \multirow{2}[0]{*}{-} & XC7Z020+ \\
            &       &       &       &       &       &       &       & XC7VX690T$\times$6 \\ %\hline
            \cite{zhang2017improving}   & INT16     & 1790      & 37.46 & 47.8  & 91    & 43    & 53    & GX1150 \\ %\hline
            \cite{lu2017evaluating}     & INT16     & 2940.7    & 23.6  & 124.6 &   -   &   -   &   -   & ZCU102 \\ %\hline
            \cite{aydonat2017opencl}    & FP16      & 1382      & 45    & 30.7  & 97    & 58    & 92    & GX1150 \\ %\hline
            \cite{podili2017fast}       & INT32     & 229       & 8.04  & 28.5  & 100   & 84    & 18    & Stratix V \\ %\hline            
            \cite{guan2017fpga}         & FP32      & 7.26      & 19.63 & 0.37  & 42    & 65    & 52    & XC7VX485T \\ %\hline
            \cite{zhang2015optimizing}  & FP32      & 61.62     & 18.61 & 3.3   & 80    & 61    & 50    & XC7VX485T \\ %\hline
            \cite{zhang2017frequency}   & FP32      & 123.5     & 13.18 & 9.37  & 88    & 85    & 64    & Stratix V \\ %\hline
            \cite{zhang2017improving}   & FP32      & 866       & 41.73 & 20.75 & 87    & -     & 46    & GX1150 \\ 
            \bottomrule
        \end{tabular}%
    \label{tab:hardware_list}%
  \end{table}%